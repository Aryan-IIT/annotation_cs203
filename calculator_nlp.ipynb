{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>text</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T16:25:26.929162Z</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...</td>\n",
       "      <td>1378.586</td>\n",
       "      <td>भारत के पूर्वोत्तर राज्यों में internet का एक ...</td>\n",
       "      <td>2025-01-24T16:25:26.929178Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T16:22:55.095999Z</td>\n",
       "      <td>2</td>\n",
       "      <td>[{\"start\":0,\"end\":2,\"text\":\"आज\",\"labels\":[\"ADV...</td>\n",
       "      <td>455.641</td>\n",
       "      <td>आज भारत में हम Space Technology का इस्तेमाल गर...</td>\n",
       "      <td>2025-01-24T16:22:55.096014Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T16:25:23.353033Z</td>\n",
       "      <td>3</td>\n",
       "      <td>[{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET...</td>\n",
       "      <td>115.451</td>\n",
       "      <td>इस वर्ष मार्च में दिल्ली में International Sol...</td>\n",
       "      <td>2025-01-24T16:25:23.353048Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T17:18:15.053771Z</td>\n",
       "      <td>4</td>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"इसके\",\"labels\":[\"D...</td>\n",
       "      <td>3197.933</td>\n",
       "      <td>इसके अलावा दिग्लीपुर, Car Nicobar और Campbell-...</td>\n",
       "      <td>2025-01-24T17:25:34.416729Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T18:37:41.746239Z</td>\n",
       "      <td>5</td>\n",
       "      <td>[{\"start\":0,\"end\":6,\"text\":\"स्वराज\",\"labels\":[...</td>\n",
       "      <td>4311.570</td>\n",
       "      <td>स्वराज द्वीप, शहीद द्वीप और Long Island में Pa...</td>\n",
       "      <td>2025-01-24T18:37:41.746261Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at  id  \\\n",
       "0             66          1  2025-01-24T16:25:26.929162Z   1   \n",
       "1             64          1  2025-01-24T16:22:55.095999Z   2   \n",
       "2             65          1  2025-01-24T16:25:23.353033Z   3   \n",
       "3             67          1  2025-01-24T17:18:15.053771Z   4   \n",
       "4             68          1  2025-01-24T18:37:41.746239Z   5   \n",
       "\n",
       "                                               label  lead_time  \\\n",
       "0  [{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...   1378.586   \n",
       "1  [{\"start\":0,\"end\":2,\"text\":\"आज\",\"labels\":[\"ADV...    455.641   \n",
       "2  [{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET...    115.451   \n",
       "3  [{\"start\":0,\"end\":4,\"text\":\"इसके\",\"labels\":[\"D...   3197.933   \n",
       "4  [{\"start\":0,\"end\":6,\"text\":\"स्वराज\",\"labels\":[...   4311.570   \n",
       "\n",
       "                                                text  \\\n",
       "0  भारत के पूर्वोत्तर राज्यों में internet का एक ...   \n",
       "1  आज भारत में हम Space Technology का इस्तेमाल गर...   \n",
       "2  इस वर्ष मार्च में दिल्ली में International Sol...   \n",
       "3  इसके अलावा दिग्लीपुर, Car Nicobar और Campbell-...   \n",
       "4  स्वराज द्वीप, शहीद द्वीप और Long Island में Pa...   \n",
       "\n",
       "                    updated_at  \n",
       "0  2025-01-24T16:25:26.929178Z  \n",
       "1  2025-01-24T16:22:55.096014Z  \n",
       "2  2025-01-24T16:25:23.353048Z  \n",
       "3  2025-01-24T17:25:34.416729Z  \n",
       "4  2025-01-24T18:37:41.746261Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = \"annotations/\"\n",
    "file_names = [\"nlp_aryan.csv\", \"nlp_parthiv.csv\"]\n",
    "\n",
    "df_aryan = pd.read_csv(data_directory + file_names[0])\n",
    "df_parthiv = pd.read_csv(data_directory + file_names[1])\n",
    "\n",
    "df_aryan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, observe how the only relevant column is the one that is named as **label**. \n",
    "Additonally, note that, our input sentences, from the csv, are in the same order for both annotated csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    \"\"\"\n",
    "    Transforms the input dataframe into the needed format for word to label comparison.\n",
    "    \"\"\"\n",
    "    transformed_df = df[['label']].rename(columns={'label': 'sample'})\n",
    "    transformed_df['sample'] = transformed_df['sample'].astype(str)\n",
    "    \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_aryan = transform_df(df_aryan)\n",
    "transformed_df_parthiv = transform_df(df_parthiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"start\":3,\"end\":8,\"text\":\"भारत \",\"labels\":[\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"start\":0,\"end\":3,\"text\":\"इस \",\"labels\":[\"DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"start\":0,\"end\":5,\"text\":\"इसके \",\"labels\":[\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"start\":0,\"end\":7,\"text\":\"स्वराज \",\"labels\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample\n",
       "0  [{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...\n",
       "1  [{\"start\":3,\"end\":8,\"text\":\"भारत \",\"labels\":[\"...\n",
       "2  [{\"start\":0,\"end\":3,\"text\":\"इस \",\"labels\":[\"DE...\n",
       "3  [{\"start\":0,\"end\":5,\"text\":\"इसके \",\"labels\":[\"...\n",
       "4  [{\"start\":0,\"end\":7,\"text\":\"स्वराज \",\"labels\":..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df_parthiv.head() #we extracted the relevant column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_create_dict(sample):\n",
    "    \"\"\"Clean spaces in text and create a word-to-label dictionary.\"\"\"\n",
    "    word_label_dict = {}\n",
    "    data = json.loads(sample)\n",
    "    for entry in data:\n",
    "        word = entry[\"text\"].strip()  #removing whitespace \n",
    "        label = entry[\"labels\"][0]   #every word has one label, so accessing it. \n",
    "        word_label_dict[word] = label\n",
    "    return word_label_dict\n",
    "\n",
    "def compare_dictionaries(dict1, dict2):\n",
    "    \"\"\"Compare two word-label dictionaries and return matching and mismatching labels.\"\"\"\n",
    "    all_labels1, all_labels2 = [], []\n",
    "    for word in dict1:\n",
    "        if word in dict2:  #match only if the word exists in both\n",
    "            all_labels1.append(dict1[word])\n",
    "            all_labels2.append(dict2[word])\n",
    "    return all_labels1, all_labels2\n",
    "\n",
    "df1 = transformed_df_aryan\n",
    "df2 = transformed_df_parthiv\n",
    "df1[\"word_label_dict\"] = df1[\"sample\"].apply(clean_and_create_dict)\n",
    "df2[\"word_label_dict\"] = df2[\"sample\"].apply(clean_and_create_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa from confusion matrix calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels1, all_labels2 = [], []\n",
    "\n",
    "for idx in range(len(df1)):\n",
    "    labels1, labels2 = compare_dictionaries(df1.loc[idx, \"word_label_dict\"], df2.loc[idx, \"word_label_dict\"])\n",
    "    all_labels1.extend(labels1)\n",
    "    all_labels2.extend(labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing labels from df1 vs df2\n",
    "\n",
    "Here we can view that there are a few differences in annotations, but otherwise the annotation is similiar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN', 'ADP', 'ADV', 'NOUN', 'ADP', 'NOUN', 'ADP', 'NUM', 'NOUN', 'PROPN']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'NUM', 'NOUN', 'PROPN']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric calculations \n",
    "Using inbuilt sklearn function for calculation of Confusion matrix and cohen's kappa co-efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cohen's Kappa Score: 0.8564991092325427\n",
      "\n",
      "Summary:\n",
      "Total Words Compared: 316\n",
      "Agreement: 277\n",
      "Disagreement: 39\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(set(all_labels1 + all_labels2))\n",
    "conf_matrix = confusion_matrix(all_labels1, all_labels2, labels=labels)\n",
    "kappa_score = cohen_kappa_score(all_labels1, all_labels2)\n",
    "\n",
    "print(\"\\nCohen's Kappa Score:\", kappa_score)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total Words Compared: {len(all_labels1)}\")\n",
    "print(f\"Agreement: {sum(np.array(all_labels1) == np.array(all_labels2))}\")\n",
    "print(f\"Disagreement: {sum(np.array(all_labels1) != np.array(all_labels2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRON_WH</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON_WH</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ADJ  ADP  ADV  CONJ  DET  NOUN  NUM  PART  PRON  PRON_WH  PROPN  \\\n",
       "ADJ       16    0    1     0    0     0    0     0     0        0      0   \n",
       "ADP        4   52    0     1    0     0    0     0     0        0      0   \n",
       "ADV        2    3    8     0    0     1    0     0     0        0      0   \n",
       "CONJ       1    0    0     9    0     0    0     0     0        0      0   \n",
       "DET        0    0    0     0    6     0    4     0     0        0      0   \n",
       "NOUN       0    0    0     0    0    63    0     0     0        0      3   \n",
       "NUM        0    0    0     0    0     0    9     0     0        0      0   \n",
       "PART       0    0    0     0    0     0    0     0     0        0      0   \n",
       "PRON       0    0    0     0    1     0    0     0    10        0      0   \n",
       "PRON_WH    0    0    0     0    0     0    0     0     0        1      0   \n",
       "PROPN      2    0    0     0    0     2    0     0     0        0     40   \n",
       "VERB       1    0    1     0    0     3    0     0     0        0      0   \n",
       "X          0    0    0     0    0     0    0     0     0        0      0   \n",
       "\n",
       "         VERB   X  \n",
       "ADJ         0   0  \n",
       "ADP         0   0  \n",
       "ADV         0   0  \n",
       "CONJ        0   0  \n",
       "DET         0   0  \n",
       "NOUN        6   0  \n",
       "NUM         0   0  \n",
       "PART        1   0  \n",
       "PRON        0   0  \n",
       "PRON_WH     0   0  \n",
       "PROPN       0   0  \n",
       "VERB       44   2  \n",
       "X           0  19  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "pd.DataFrame(conf_matrix, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>word_label_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"start\":0,\"end\":7,\"text\":\"स्वराज \",\"labels\":...</td>\n",
       "      <td>{'स्वराज': 'ADJ', 'द्वीप': 'PROPN'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  \\\n",
       "0  [{\"start\":0,\"end\":7,\"text\":\"स्वराज \",\"labels\":...   \n",
       "\n",
       "                       word_label_dict  \n",
       "0  {'स्वराज': 'ADJ', 'द्वीप': 'PROPN'}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET\"]},{\"start\":3,\"end\":7,\"text\":\"वर्ष\",\"labels\":[\"NOUN\"]},{\"start\":8,\"end\":13,\"text\":\"मार्च\",\"labels\":[\"PROPN\"]},{\"start\":14,\"end\":17,\"text\":\"में\",\"labels\":[\"ADP\"]},{\"start\":18,\"end\":24,\"text\":\"दिल्ली\",\"labels\":[\"PROPN\"]},{\"start\":25,\"end\":28,\"text\":\"में\",\"labels\":[\"ADP\"]},{\"start\":29,\"end\":57,\"text\":\"International Solar Alliance\",\"labels\":[\"PROPN\"]},{\"start\":58,\"end\":60,\"text\":\"का\",\"labels\":[\"ADP\"]},{\"start\":61,\"end\":67,\"text\":\"summit\",\"labels\":[\"NOUN\"]},{\"start\":68,\"end\":71,\"text\":\"हुआ\",\"labels\":[\"VERB\"]},{\"start\":71,\"end\":72,\"text\":\"।\",\"labels\":[\"X\"]}]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aryan = df_aryan.loc[:, df_aryan.columns.intersection(['id','label'])]\n",
    "df_aryan.iloc[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [373, 353]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m label_to_index \u001b[38;5;241m=\u001b[39m {label: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_labels)}  \u001b[38;5;66;03m# Map labels to indices\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maryan_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparthiv_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Display confusion matrix\u001b[39;00m\n\u001b[1;32m     27\u001b[0m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mconf_matrix, display_labels\u001b[38;5;241m=\u001b[39munique_labels)\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Academics /Semester 4/AI Software tools and techniques/annotation_cs203/venv_name/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Academics /Semester 4/AI Software tools and techniques/annotation_cs203/venv_name/lib/python3.10/site-packages/sklearn/metrics/_classification.py:340\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 340\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/Desktop/Academics /Semester 4/AI Software tools and techniques/annotation_cs203/venv_name/lib/python3.10/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Academics /Semester 4/AI Software tools and techniques/annotation_cs203/venv_name/lib/python3.10/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [373, 353]"
     ]
    }
   ],
   "source": [
    "# Step 1: Preprocess the data and extract labels\n",
    "def extract_labels(df):\n",
    "    all_labels = []\n",
    "    for row in df[\"label\"]:\n",
    "        annotations = json.loads(row)\n",
    "        labels = [annotation[\"labels\"][0] for annotation in annotations]\n",
    "        # Extract the first label from each annotation\n",
    "        all_labels.extend(labels)  # Flatten into a single list\n",
    "    return all_labels\n",
    "\n",
    "# Extract labels\n",
    "aryan_labels = extract_labels(df_aryan)\n",
    "parthiv_labels = extract_labels(df_parthiv)\n",
    "\n",
    "# Step 2: Build the confusion matrix\n",
    "unique_labels = sorted(set(aryan_labels + parthiv_labels))  # Get all unique labels\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}  # Map labels to indices\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(\n",
    "    [label_to_index[label] for label in aryan_labels],\n",
    "    [label_to_index[label] for label in parthiv_labels],\n",
    "    labels=range(len(unique_labels))\n",
    ")\n",
    "\n",
    "# Display confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=unique_labels).plot(cmap=\"viridis\")\n",
    "\n",
    "# Step 3: Calculate Cohen's Kappa\n",
    "def cohen_kappa(conf_matrix):\n",
    "    # Observed agreement (P_o)\n",
    "    total_items = conf_matrix.sum()\n",
    "    observed_agreement = np.trace(conf_matrix) / total_items\n",
    "    \n",
    "    # Expected agreement (P_e)\n",
    "    row_sums = conf_matrix.sum(axis=1)\n",
    "    col_sums = conf_matrix.sum(axis=0)\n",
    "    expected_agreement = np.sum((row_sums * col_sums) / total_items) / total_items\n",
    "    \n",
    "    # Cohen's Kappa formula\n",
    "    kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement)\n",
    "    return kappa\n",
    "\n",
    "# Calculate and print Cohen's Kappa\n",
    "kappa = cohen_kappa(conf_matrix)\n",
    "print(f\"Cohen's Kappa: {kappa}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
