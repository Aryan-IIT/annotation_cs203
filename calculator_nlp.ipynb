{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>text</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T16:25:26.929162Z</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...</td>\n",
       "      <td>1378.586</td>\n",
       "      <td>भारत के पूर्वोत्तर राज्यों में internet का एक ...</td>\n",
       "      <td>2025-01-24T16:25:26.929178Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T16:22:55.095999Z</td>\n",
       "      <td>2</td>\n",
       "      <td>[{\"start\":0,\"end\":2,\"text\":\"आज\",\"labels\":[\"ADV...</td>\n",
       "      <td>455.641</td>\n",
       "      <td>आज भारत में हम Space Technology का इस्तेमाल गर...</td>\n",
       "      <td>2025-01-24T16:22:55.096014Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T16:25:23.353033Z</td>\n",
       "      <td>3</td>\n",
       "      <td>[{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET...</td>\n",
       "      <td>115.451</td>\n",
       "      <td>इस वर्ष मार्च में दिल्ली में International Sol...</td>\n",
       "      <td>2025-01-24T16:25:23.353048Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T17:18:15.053771Z</td>\n",
       "      <td>4</td>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"इसके\",\"labels\":[\"D...</td>\n",
       "      <td>3197.933</td>\n",
       "      <td>इसके अलावा दिग्लीपुर, Car Nicobar और Campbell-...</td>\n",
       "      <td>2025-01-24T17:25:34.416729Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-24T18:37:41.746239Z</td>\n",
       "      <td>5</td>\n",
       "      <td>[{\"start\":0,\"end\":6,\"text\":\"स्वराज\",\"labels\":[...</td>\n",
       "      <td>4311.570</td>\n",
       "      <td>स्वराज द्वीप, शहीद द्वीप और Long Island में Pa...</td>\n",
       "      <td>2025-01-24T18:37:41.746261Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at  id  \\\n",
       "0             66          1  2025-01-24T16:25:26.929162Z   1   \n",
       "1             64          1  2025-01-24T16:22:55.095999Z   2   \n",
       "2             65          1  2025-01-24T16:25:23.353033Z   3   \n",
       "3             67          1  2025-01-24T17:18:15.053771Z   4   \n",
       "4             68          1  2025-01-24T18:37:41.746239Z   5   \n",
       "\n",
       "                                               label  lead_time  \\\n",
       "0  [{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...   1378.586   \n",
       "1  [{\"start\":0,\"end\":2,\"text\":\"आज\",\"labels\":[\"ADV...    455.641   \n",
       "2  [{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET...    115.451   \n",
       "3  [{\"start\":0,\"end\":4,\"text\":\"इसके\",\"labels\":[\"D...   3197.933   \n",
       "4  [{\"start\":0,\"end\":6,\"text\":\"स्वराज\",\"labels\":[...   4311.570   \n",
       "\n",
       "                                                text  \\\n",
       "0  भारत के पूर्वोत्तर राज्यों में internet का एक ...   \n",
       "1  आज भारत में हम Space Technology का इस्तेमाल गर...   \n",
       "2  इस वर्ष मार्च में दिल्ली में International Sol...   \n",
       "3  इसके अलावा दिग्लीपुर, Car Nicobar और Campbell-...   \n",
       "4  स्वराज द्वीप, शहीद द्वीप और Long Island में Pa...   \n",
       "\n",
       "                    updated_at  \n",
       "0  2025-01-24T16:25:26.929178Z  \n",
       "1  2025-01-24T16:22:55.096014Z  \n",
       "2  2025-01-24T16:25:23.353048Z  \n",
       "3  2025-01-24T17:25:34.416729Z  \n",
       "4  2025-01-24T18:37:41.746261Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = \"annotations/\"\n",
    "file_names = [\"nlp_aryan.csv\", \"nlp_parthiv.csv\"]\n",
    "\n",
    "df_aryan = pd.read_csv(data_directory + file_names[0])\n",
    "df_parthiv = pd.read_csv(data_directory + file_names[1])\n",
    "\n",
    "df_aryan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, observe how the only relevant column is the one that is named as **label**. \n",
    "Additonally, note that, our input sentences, from the csv, are in the same order for both annotated csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    \"\"\"\n",
    "    Transforms the input dataframe into the needed format for word to label comparison.\n",
    "    \"\"\"\n",
    "    transformed_df = df[['label']].rename(columns={'label': 'sample'})\n",
    "    transformed_df['sample'] = transformed_df['sample'].astype(str)\n",
    "    \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_aryan = transform_df(df_aryan)\n",
    "transformed_df_parthiv = transform_df(df_parthiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"start\":3,\"end\":8,\"text\":\"भारत \",\"labels\":[\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"start\":0,\"end\":3,\"text\":\"इस \",\"labels\":[\"DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"start\":0,\"end\":5,\"text\":\"इसके \",\"labels\":[\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"start\":0,\"end\":7,\"text\":\"स्वराज \",\"labels\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample\n",
       "0  [{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...\n",
       "1  [{\"start\":3,\"end\":8,\"text\":\"भारत \",\"labels\":[\"...\n",
       "2  [{\"start\":0,\"end\":3,\"text\":\"इस \",\"labels\":[\"DE...\n",
       "3  [{\"start\":0,\"end\":5,\"text\":\"इसके \",\"labels\":[\"...\n",
       "4  [{\"start\":0,\"end\":7,\"text\":\"स्वराज \",\"labels\":..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df_parthiv.head() #we extracted the relevant column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_create_dict(sample):\n",
    "    \"\"\"Clean spaces in text and create a word-to-label dictionary.\"\"\"\n",
    "    word_label_dict = {}\n",
    "    data = json.loads(sample)\n",
    "    for entry in data:\n",
    "        word = entry[\"text\"].strip()  #removing whitespace \n",
    "        label = entry[\"labels\"][0]   #every word has one label, so accessing it. \n",
    "        word_label_dict[word] = label\n",
    "    return word_label_dict\n",
    "\n",
    "def compare_dictionaries(dict1, dict2):\n",
    "    \"\"\"Compare two word-label dictionaries and return matching and mismatching labels.\"\"\"\n",
    "    all_labels1, all_labels2 = [], []\n",
    "    for word in dict1:\n",
    "        if word in dict2:  #match only if the word exists in both\n",
    "            all_labels1.append(dict1[word])\n",
    "            all_labels2.append(dict2[word])\n",
    "    return all_labels1, all_labels2\n",
    "\n",
    "df1 = transformed_df_aryan\n",
    "df2 = transformed_df_parthiv\n",
    "df1[\"word_label_dict\"] = df1[\"sample\"].apply(clean_and_create_dict)\n",
    "df2[\"word_label_dict\"] = df2[\"sample\"].apply(clean_and_create_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>word_label_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...</td>\n",
       "      <td>{'भारत': 'PROPN', 'के': 'ADP', 'पूर्वोत्तर': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"start\":0,\"end\":2,\"text\":\"आज\",\"labels\":[\"ADV...</td>\n",
       "      <td>{'आज': 'ADV', 'भारत': 'PROPN', 'में': 'ADP', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET...</td>\n",
       "      <td>{'इस': 'DET', 'वर्ष': 'NOUN', 'मार्च': 'PROPN'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"start\":0,\"end\":4,\"text\":\"इसके\",\"labels\":[\"D...</td>\n",
       "      <td>{'इसके': 'DET', 'अलावा': 'ADP', 'दिग्लीपुर': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"start\":0,\"end\":6,\"text\":\"स्वराज\",\"labels\":[...</td>\n",
       "      <td>{'स्वराज': 'PROPN', 'द्वीप': 'PROPN', ',': 'X'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  \\\n",
       "0  [{\"start\":0,\"end\":4,\"text\":\"भारत\",\"labels\":[\"P...   \n",
       "1  [{\"start\":0,\"end\":2,\"text\":\"आज\",\"labels\":[\"ADV...   \n",
       "2  [{\"start\":0,\"end\":2,\"text\":\"इस\",\"labels\":[\"DET...   \n",
       "3  [{\"start\":0,\"end\":4,\"text\":\"इसके\",\"labels\":[\"D...   \n",
       "4  [{\"start\":0,\"end\":6,\"text\":\"स्वराज\",\"labels\":[...   \n",
       "\n",
       "                                     word_label_dict  \n",
       "0  {'भारत': 'PROPN', 'के': 'ADP', 'पूर्वोत्तर': '...  \n",
       "1  {'आज': 'ADV', 'भारत': 'PROPN', 'में': 'ADP', '...  \n",
       "2  {'इस': 'DET', 'वर्ष': 'NOUN', 'मार्च': 'PROPN'...  \n",
       "3  {'इसके': 'DET', 'अलावा': 'ADP', 'दिग्लीपुर': '...  \n",
       "4  {'स्वराज': 'PROPN', 'द्वीप': 'PROPN', ',': 'X'...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head() #here observe how the words and their indices are not all relevant, hence we map a dictionary from our exsting sample string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa from confusion matrix calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels1, all_labels2 = [], []\n",
    "\n",
    "for idx in range(len(df1)):\n",
    "    labels1, labels2 = compare_dictionaries(df1.loc[idx, \"word_label_dict\"], df2.loc[idx, \"word_label_dict\"])\n",
    "    all_labels1.extend(labels1)\n",
    "    all_labels2.extend(labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing labels from df1 vs df2\n",
    "\n",
    "Here we can view that there are a few differences in annotations, but otherwise the annotation is similiar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN', 'ADP', 'ADV', 'NOUN', 'ADP', 'NOUN', 'ADP', 'NUM', 'NOUN', 'PROPN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADP', 'NUM', 'NOUN', 'PROPN']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric calculations \n",
    "Using inbuilt sklearn function for calculation of Confusion matrix and cohen's kappa co-efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(set(all_labels1 + all_labels2))\n",
    "confuse_matrix = confusion_matrix(all_labels1, all_labels2, labels=labels)\n",
    "c_kappa_score = cohen_kappa_score(all_labels1, all_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cohen's Kappa Score: 0.8529\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCohen's Kappa Score:\", round(c_kappa_score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PART_NEG</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRON_WH</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART_NEG</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON_WH</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ADJ  ADP  ADV  CONJ  DET  NOUN  NUM  PART  PART_NEG  PRON  PRON_WH  \\\n",
       "ADJ        16    0    1     0    0     0    0     0         0     0        0   \n",
       "ADP         4   51    0     1    0     0    0     0         0     0        0   \n",
       "ADV         2    3    8     0    0     1    0     0         0     0        0   \n",
       "CONJ        1    0    0     9    0     0    0     0         0     0        0   \n",
       "DET         0    0    0     0    6     0    4     0         0     0        0   \n",
       "NOUN        0    0    0     0    0    63    0     0         0     0        0   \n",
       "NUM         0    0    0     0    0     0    9     0         0     0        0   \n",
       "PART        0    0    0     0    0     0    0     0         0     0        0   \n",
       "PART_NEG    0    1    0     0    0     0    0     0         0     0        0   \n",
       "PRON        0    0    0     0    1     0    0     0         0    10        0   \n",
       "PRON_WH     0    0    0     0    0     0    0     0         0     0        1   \n",
       "PROPN       2    0    0     0    0     2    0     0         0     0        0   \n",
       "VERB        1    0    1     0    0     3    0     0         0     0        0   \n",
       "X           0    0    0     0    0     0    0     0         0     0        0   \n",
       "\n",
       "          PROPN  VERB   X  \n",
       "ADJ           0     0   0  \n",
       "ADP           0     0   0  \n",
       "ADV           0     0   0  \n",
       "CONJ          0     0   0  \n",
       "DET           0     0   0  \n",
       "NOUN          3     6   0  \n",
       "NUM           0     0   0  \n",
       "PART          0     1   0  \n",
       "PART_NEG      0     0   0  \n",
       "PRON          0     0   0  \n",
       "PRON_WH       0     0   0  \n",
       "PROPN        40     0   0  \n",
       "VERB          0    44   2  \n",
       "X             0     0  19  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "pd.DataFrame(confuse_matrix, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can observe how this is a \"diagonal heavy\" matrix. This means, that both the annotators, Aryan and Parthiv mostly agree on things. \n",
    "\n",
    "Additionally, we can note, that there are a few dis-agreements, like Part_neg (Negative particle) and Part (particle). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words Compared: 316\n",
      "Agreement: 276\n",
      "Disagreement: 40\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Words Compared: {len(all_labels1)}\")\n",
    "print(f\"Agreement: {sum(np.array(all_labels1) == np.array(all_labels2))}\")\n",
    "print(f\"Disagreement: {sum(np.array(all_labels1) != np.array(all_labels2))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
